# DeepSeek-R1-Distill-Qwen-14B â€” smaller reasoning model
model: /seagate/models/DeepSeek-R1-Distill-Qwen-14B-Q6_K_L.gguf
benchmarks: [lcb]
temperature: 0.6
max_tokens: 10000
context_size: 32768
lcb:
  problems_file: test6.jsonl

# Qwen2.5-Coder-32B â€” coding-specific, non-thinking
model: /seagate/models/Qwen2.5-Coder-32B-Instruct-Q4_K_M.gguf
benchmarks: [lcb]
temperature: 0.0
max_tokens: 1000
context_size: 4096
gpu_layers: 80
top_p: 0.9
min_p: 0.1
problems_file: test5.jsonl
save_raw: true

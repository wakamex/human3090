# QwQ-32B â€” reasoning model
model: /seagate/models/QwQ-32B-Q4_K_M.gguf
benchmarks: [lcb]
temperature: 0.6
max_tokens: 10000
context_size: 32768
lcb:
  problems_file: test6.jsonl
